{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\Yv}{\\mathbf{Y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\betav}{\\mathbf{\\beta}}\n",
    "\\newcommand{\\gv}{\\mathbf{g}}\n",
    "\\newcommand{\\Hv}{\\mathbf{H}}\n",
    "\\newcommand{\\dv}{\\mathbf{d}}\n",
    "\\newcommand{\\Vv}{\\mathbf{V}}\n",
    "\\newcommand{\\vv}{\\mathbf{v}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\Sv}{\\mathbf{S}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\Zv}{\\mathbf{Z}}\n",
    "\\newcommand{\\Norm}{\\mathcal{N}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "\\newcommand{\\grad}{\\mathbf{\\nabla}}\n",
    "\\newcommand{\\ebx}[1]{e^{\\wv_{#1}^T \\xv_n}}\n",
    "\\newcommand{\\eby}[1]{e^{y_{n,#1}}}\n",
    "\\newcommand{\\Tiv}{\\mathbf{Ti}}\n",
    "\\newcommand{\\Fv}{\\mathbf{F}}\n",
    "\\newcommand{\\ones}[1]{\\mathbf{1}_{#1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UNCLASSIFIED \n",
    "_Distribution A_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data exploration and visualization for NASA data\n",
    "data gathered from: https://c3.ndc.nasa.gov/dashlink/projects/85/resources/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this file is to figure out the format of the matlab files with the intention of converting them\n",
    "to panda dataframes and saving them in a parquet format.  all files that were downloaded are in matlab (.mat) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import dateutil\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters Contained in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'VAR_1107', 'VAR_2670', 'VAR_5107', 'VAR_6670', 'FPAC', 'BLAC', 'CTAC', 'TH', 'MH', 'EGT_1', 'EGT_2', 'EGT_3', 'EGT_4', 'IVV', 'GS', 'TRK', 'TRKM', 'DA', 'POVT', 'WS', 'MW', 'DFGS', 'WD', 'ALT', 'NSQT', 'RALT', 'ALTR', 'FQTY_1', 'OIT_1', 'OIT_2', 'AOA1', 'AOA2', 'PTCH', 'FF_1', 'PSA', 'FF_2', 'FF_3', 'ROLL', 'FF_4', 'N1_1', 'N1_2', 'MACH', 'CAS', 'APFD', 'PH', 'CASM', 'TAS', 'VRTG', 'LATG', 'PI', 'PS', 'N1_3', 'EVNT', 'MRK', 'VIB_1', 'PT', 'VHF1', 'VHF2', 'LGDN', 'LGUP', 'VIB_2', 'VHF3', 'PUSH', 'SHKR', 'MSQT_2', 'VIB_3', 'LONG', 'PLA_1', 'N1_4', 'HYDY', 'HYDG', 'SMOK', 'CALT', 'VIB_4', 'PLA_2', 'PLA_3', 'PLA_4', 'GMT_HOUR', 'GMT_MINUTE', 'GMT_SEC', 'ACMT', 'FQTY_2', 'OIT_3', 'OIT_4', 'DATE_YEAR', 'DATE_MONTH', 'DATE_DAY', 'DVER_1', 'ACID', 'BLV', 'EAI', 'PACK', 'AOAI', 'AOAC', 'BAL1', 'APUF', 'TOCW', 'BAL2', 'WSHR', 'WOW', 'N2_1', 'N2_2', 'N2_3', 'N2_4', 'TAT', 'SAT', 'N1T', 'N1C', 'RUDD', 'FQTY_3', 'OIP_1', 'OIP_2', 'FQTY_4', 'CRSS', 'HDGS', 'ALTS', 'SNAP', 'CASS', 'N1CO', 'VSPS', 'MNS', 'MSQT_1', 'VMODE', 'LMOD', 'A_T', 'CCPC', 'CCPF', 'RUDP', 'CWPC', 'CWPF', 'OIP_3', 'OIP_4', 'LOC', 'GLS', 'LONP', 'ABRK', 'AIL_1', 'AIL_2', 'SPL_1', 'SPL_2', 'ESN_4', 'ECYC_1', 'ECYC_2', 'ELEV_1', 'ELEV_2', 'FLAP', 'PTRM', 'HF1', 'HF2', 'SMKB', 'SPLY', 'SPLG', 'FRMC', 'DVER_2', 'ESN_3', 'BPGR_1', 'BPGR_2', 'BPYR_1', 'BPYR_2', 'ECYC_3', 'ECYC_4', 'EHRS_1', 'TCAS', 'GPWS', 'TMAG', 'TAI', 'WAI_1', 'WAI_2', 'DWPT', 'OIPL', 'FADF', 'FADS', 'EHRS_4', 'EHRS_3', 'EHRS_2', 'TMODE', 'ATEN', 'LATP', 'FIRE_1', 'FIRE_2', 'FIRE_3', 'FIRE_4', 'FGC3', 'ILSF', 'ESN_1', 'ESN_2'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = loadmat('Tail_687_1/687200104111158.mat')\n",
    "data1 = loadmat('Tail_654_4/654200204300312.mat')\n",
    "k = data1.keys()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## All dictionary values are made of an numpy ndarray of objects\n",
    "### They all have the objects named 'data', 'Rate', 'Units', 'Description', 'Alpha'\n",
    "#### With the exception of the '__header__', '__version__', '__globals__' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "('data', 'Rate', 'Units', 'Description', 'Alpha')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(data1[k].dtype.names) for k in data1.keys() if type(data1[k]) == np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header = :b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Tue Jan 28 10:26:54 2014'\n",
      "version = :1.0\n",
      "globals = :[]\n"
     ]
    }
   ],
   "source": [
    "header = data1['__header__']\n",
    "version = data1['__version__']\n",
    "gs = data1['__globals__']\n",
    "print(f'header = :{header}')\n",
    "print(f'version = :{version}')\n",
    "print(f'globals = :{gs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and formatting Metadata for the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fdir = 'Tail_687_1'\n",
    "\n",
    "file = '687200104111158'\n",
    "metadata = []\n",
    "metadata = defaultdict(dict)\n",
    "\n",
    "#filelist = os.listdir(fdir)\n",
    "filelist = [(f'{file}.mat')]\n",
    "#print(len(filelist))\n",
    "#for f in filelist[0:12]:\n",
    "for f in filelist:\n",
    "    #print(f)\n",
    "    d = loadmat((f'{fdir}/{f}'))\n",
    "    year   = d['DATE_YEAR'][0][0][0][:]\n",
    "    month  = d['DATE_MONTH'][0][0][0][:]\n",
    "    day    = d['DATE_DAY'][0][0][0][:]\n",
    "    hour   = d['GMT_HOUR'][0][0][0][:]\n",
    "    minute = d['GMT_MINUTE'][0][0][0][:]\n",
    "    second = d['GMT_SEC'][0][0][0][:]\n",
    "    ys = min(np.unique(year))\n",
    "    ms = min(np.unique(month))\n",
    "    ds = min(np.unique(day))\n",
    "    \n",
    "    #h0s = hour[0][0].astype(float)\n",
    "    #m0s = minute[0][0].astype(float)\n",
    "    #s0s = second[0][0].astype(float)\n",
    "    #h0e = hour[-1][0].astype(float)\n",
    "    #m0e = minute[-1][0].astype(float)\n",
    "    #s0e = second[-1][0].astype(float)\n",
    "    ##starttime = timedelta(hours=h0s, minutes=m0s, seconds=s0s)\n",
    "    ##stoptime = timedelta(hours=h0e, minutes=m0e, seconds=s0e)\n",
    "    ##print(f'First file:{year[0,0]}:{month[0,0]}:{day[0,0]} Start: {starttime}, Stop {stoptime}')\n",
    "    #print(f'File {f}:   {ys}:{month[0,0]}:{day[0,0]} Start: {h0s}:{m0s}:{s0s}, Stop {h0e}:{m0e}:{s0e}')\n",
    "    if ys == 2165: \n",
    "        airbornedata = False\n",
    "    else:\n",
    "        airbornedata = True\n",
    "        \n",
    "    metadata[file]['AirborneData'] = airbornedata\n",
    "    \n",
    "    metadata[file]['StartDate'] = {}\n",
    "    metadata[file]['StartDate']['Year']  = ys.astype(str)\n",
    "    metadata[file]['StartDate']['Month'] = ms.astype(str)\n",
    "    metadata[file]['StartDate']['Day']   = ds.astype(str)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stored Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR_1107    Units: <units>   Rate: 0.25  Alpha: 1107        Description: SYNC WORD FOR SUBFRAME 1\n",
      "VAR_2670    Units: <units>   Rate: 0.25  Alpha: 2670        Description: SYNC WORD FOR SUBFRAME 2\n",
      "VAR_5107    Units: <units>   Rate: 0.25  Alpha: 5107        Description: SYNC WORD FOR SUBFRAME 3\n",
      "VAR_6670    Units: <units>   Rate: 0.25  Alpha: 6670        Description: SYNC WORD FOR SUBFRAME 4\n",
      "FPAC        Units: G         Rate: 16.0  Alpha: FPAC        Description: FLIGHT PATH ACCELERATION\n",
      "BLAC        Units: G         Rate: 16.0  Alpha: BLAC        Description: BODY LONGITUDINAL ACCELERATION\n",
      "CTAC        Units: G         Rate: 16.0  Alpha: CTAC        Description: CROSS TRACK ACCELERATION\n",
      "TH          Units: DEG       Rate: 4.0   Alpha: TH          Description: TRUE HEADING LSP\n",
      "MH          Units: DEG       Rate: 4.0   Alpha: MH          Description: MAGNETIC HEADING LSP\n",
      "EGT_1       Units: DEG       Rate: 4.0   Alpha: EGT.1       Description: EXHAUST GAS TEMPERATURE 1\n",
      "EGT_2       Units: DEG       Rate: 4.0   Alpha: EGT.2       Description: EXHAUST GAS TEMPERATURE 2\n",
      "EGT_3       Units: DEG       Rate: 4.0   Alpha: EGT.3       Description: EXHAUST GAS TEMPERATURE 3\n",
      "EGT_4       Units: DEG       Rate: 4.0   Alpha: EGT.4       Description: EXHAUST GAS TEMPERATURE 4\n",
      "IVV         Units: FT/MIN    Rate: 16.0  Alpha: IVV         Description: INERTIAL VERTICAL SPEED LSP\n",
      "GS          Units: KNOTS     Rate: 4.0   Alpha: GS          Description: GROUND SPEED LSP\n",
      "TRK         Units: DEG       Rate: 4.0   Alpha: TRK         Description: TRACK ANGLE TRUE LSP\n",
      "TRKM        Units: DEG       Rate: 4.0   Alpha: TRKM        Description: TRACK ANGLE MAG LSP\n",
      "DA          Units: DEG       Rate: 4.0   Alpha: DA          Description: DRIFT ANGLE\n",
      "POVT        Units: <none>    Rate: 1.0   Alpha: POVT        Description: PYLON OVERHEAT ALL ENGINES\n",
      "WS          Units: KNOTS     Rate: 4.0   Alpha: WS          Description: WIND SPEED\n",
      "MW          Units: <none>    Rate: 1.0   Alpha: MW          Description: MASTER WARNING\n",
      "DFGS        Units: <none>    Rate: 1.0   Alpha: DFGS        Description: DFGS 1&2 MASTER\n",
      "WD          Units: DEG       Rate: 4.0   Alpha: WD          Description: WIND DIRECTION TRUE\n",
      "ALT         Units: FEET      Rate: 4.0   Alpha: ALT         Description: PRESSURE ALTITUDE LSP\n",
      "NSQT        Units: <none>    Rate: 4.0   Alpha: NSQT        Description: SQUAT SWITCH NOSE MAIN GEAR\n",
      "RALT        Units: FEET      Rate: 8.0   Alpha: RALT        Description: RADIO ALTITUDE LSP\n",
      "ALTR        Units: FT/MIN    Rate: 4.0   Alpha: ALTR        Description: ALTITUDE RATE\n",
      "FQTY_1      Units: LBS       Rate: 1.0   Alpha: FQTY.1      Description: FUEL QUANTITY TANK 1 LSB\n",
      "OIT_1       Units: DEG       Rate: 1.0   Alpha: OIT.1       Description: OIL TEMPERATURE 1\n",
      "OIT_2       Units: DEG       Rate: 1.0   Alpha: OIT.2       Description: OIL TEMPERATURE 2\n",
      "AOA1        Units: DEG       Rate: 4.0   Alpha: AOA1        Description: ANGLE OF ATTACK 1\n",
      "AOA2        Units: DEG       Rate: 4.0   Alpha: AOA2        Description: ANGLE OF ATTACK 2\n",
      "PTCH        Units: DEG       Rate: 8.0   Alpha: PTCH        Description: PITCH ANGLE LSP\n",
      "FF_1        Units: LBS/HR    Rate: 4.0   Alpha: FF.1        Description: FUEL FLOW 1\n",
      "PSA         Units: MB        Rate: 2.0   Alpha: PSA         Description: AVARAGE STATIC PRESSURE LSP\n",
      "FF_2        Units: LBS/HR    Rate: 4.0   Alpha: FF.2        Description: FUEL FLOW 2\n",
      "FF_3        Units: LBS/HR    Rate: 4.0   Alpha: FF.3        Description: FUEL FLOW 3\n",
      "ROLL        Units: DEG       Rate: 8.0   Alpha: ROLL        Description: ROLL ANGLE LSP\n",
      "FF_4        Units: LBS/HR    Rate: 4.0   Alpha: FF.4        Description: FUEL FLOW 4\n",
      "N1_1        Units: %RPM      Rate: 4.0   Alpha: N1.1        Description: FAN SPEED 1 LSP\n",
      "N1_2        Units: %RPM      Rate: 4.0   Alpha: N1.2        Description: FAN SPEED 2 LSP\n",
      "MACH        Units: MACH      Rate: 4.0   Alpha: MACH        Description: MACH LSP  \n",
      "CAS         Units: KNOTS     Rate: 4.0   Alpha: CAS         Description: COMPUTED AIRSPEED LSP\n",
      "APFD        Units: <none>    Rate: 1.0   Alpha: APFD        Description: AP FD STATUS\n",
      "PH          Units: <none>    Rate: 1.0   Alpha: PH          Description: FLIGHT PHASE FROM ACMS\n",
      "CASM        Units: KNOTS     Rate: 4.0   Alpha: CASM        Description: MAX ALLOWABLE AIRSPEED\n",
      "TAS         Units: KNOTS     Rate: 4.0   Alpha: TAS         Description: TRUE AIRSPEED LSP\n",
      "VRTG        Units: G         Rate: 8.0   Alpha: VRTG        Description: VERTICAL ACCELERATION\n",
      "LATG        Units: G         Rate: 4.0   Alpha: LATG        Description: LATERAL ACCELERATION\n",
      "PI          Units: MB        Rate: 2.0   Alpha: PI          Description: IMPACT PRESSURE LSP\n",
      "PS          Units: IN        Rate: 2.0   Alpha: PS          Description: STATIC PRESSURE LSP\n",
      "N1_3        Units: %RPM      Rate: 4.0   Alpha: N1.3        Description: FAN SPEED 3 LSP\n",
      "EVNT        Units: <none>    Rate: 1.0   Alpha: EVNT        Description: EVENT MARKER\n",
      "MRK         Units: <none>    Rate: 1.0   Alpha: MRK         Description: MARKERS- INNER, MIDDLE, OUTER\n",
      "VIB_1       Units: IN/SEC    Rate: 4.0   Alpha: VIB.1       Description: ENGINE VIBRATION 1\n",
      "PT          Units: MB        Rate: 2.0   Alpha: PT          Description: TOTAL PRESSURE LSP\n",
      "VHF1        Units: <none>    Rate: 1.0   Alpha: VHF1        Description: VHF KEYING #1\n",
      "VHF2        Units: <none>    Rate: 1.0   Alpha: VHF2        Description: VHF KEYING #2\n",
      "LGDN        Units: <none>    Rate: 1.0   Alpha: LGDN        Description: GEARS L&R DOWN LOCKED\n",
      "LGUP        Units: <none>    Rate: 1.0   Alpha: LGUP        Description: GEARS L&R UP LOCKED\n",
      "VIB_2       Units: IN/SEC    Rate: 4.0   Alpha: VIB.2       Description: ENGINE VIBRATION 2\n",
      "VHF3        Units: <none>    Rate: 1.0   Alpha: VHF3        Description: VHF KEYING #3\n",
      "PUSH        Units: <none>    Rate: 1.0   Alpha: PUSH        Description: STICK PUSHER\n",
      "SHKR        Units: <none>    Rate: 2.0   Alpha: SHKR        Description: STICK SHAKER\n",
      "MSQT_2      Units: <none>    Rate: 2.0   Alpha: MSQT.2      Description: SQUAT SWITCH RIGHT MAIN GEAR\n",
      "VIB_3       Units: IN/SEC    Rate: 4.0   Alpha: VIB.3       Description: ENGINE VIBRATION 3\n",
      "LONG        Units: G         Rate: 4.0   Alpha: LONG        Description: LONGITUDINAL ACCELERATION\n",
      "PLA_1       Units: DEG       Rate: 4.0   Alpha: PLA.1       Description: POWER LEVER ANGLE 1\n",
      "N1_4        Units: %RPM      Rate: 4.0   Alpha: N1.4        Description: FAN SPEED 4 LSP\n",
      "HYDY        Units: <none>    Rate: 1.0   Alpha: HYDY        Description: LOW HYDRAULIC PRESSURE YELLOW\n",
      "HYDG        Units: <none>    Rate: 1.0   Alpha: HYDG        Description: LOW HYDRAULIC PRESSURE GREEN\n",
      "SMOK        Units: <none>    Rate: 1.0   Alpha: SMOK        Description: SMOKE WARNING\n",
      "CALT        Units: <none>    Rate: 1.0   Alpha: CALT        Description: CABIN HIGH ALTITUDE\n",
      "VIB_4       Units: IN/SEC    Rate: 4.0   Alpha: VIB.4       Description: ENGINE VIBRATION 4\n",
      "PLA_2       Units: DEG       Rate: 4.0   Alpha: PLA.2       Description: POWER LEVER ANGLE 2\n",
      "PLA_3       Units: DEG       Rate: 4.0   Alpha: PLA.3       Description: POWER LEVER ANGLE 3\n",
      "PLA_4       Units: DEG       Rate: 4.0   Alpha: PLA.4       Description: POWER LEVER ANGLE 4\n",
      "GMT_HOUR    Units: Hour      Rate: 2.0   Alpha: GMT.HOUR    Description: GREENWICH MEAN TIME (HOUR)\n",
      "GMT_MINUTE  Units: Minute    Rate: 2.0   Alpha: GMT.MINUTE  Description: GREENWICH MEAN TIME (MINUTE)\n",
      "GMT_SEC     Units: Second    Rate: 2.0   Alpha: GMT.SEC     Description: GREENWICH MEAN TIME (SECOND)\n",
      "ACMT        Units: <none>    Rate: 1.0   Alpha: ACMT        Description: ACMS TIMING USED T1HZ\n",
      "FQTY_2      Units: LSB       Rate: 1.0   Alpha: FQTY.2      Description: FUEL QUANTITY TANK 2 LSB\n",
      "OIT_3       Units: DEG       Rate: 1.0   Alpha: OIT.3       Description: OIL TEMPERATURE 3\n",
      "OIT_4       Units: DEG       Rate: 1.0   Alpha: OIT.4       Description: OIL TEMPERATURE 4\n",
      "DATE_YEAR   Units: Year      Rate: 0.25  Alpha: DATE.YEAR   Description: Date (Year)\n",
      "DATE_MONTH  Units: Month     Rate: 0.25  Alpha: DATE.MONTH  Description: Date (Month)\n",
      "DATE_DAY    Units: Day       Rate: 0.25  Alpha: DATE.DAY    Description: Date (Day)\n",
      "DVER_1      Units: <none>    Rate: 0.25  Alpha: DVER.1      Description: DATABASE ID VERSION CHAR 1\n",
      "ACID        Units: <none>    Rate: 0.25  Alpha: ACID        Description: AIRCRAFT NUMBER\n",
      "BLV         Units: <none>    Rate: 1.0   Alpha: BLV         Description: BLEED AIR ALL VALVES\n",
      "EAI         Units: <none>    Rate: 1.0   Alpha: EAI         Description: ENGINE ANTICE ALL POSITIONS\n",
      "PACK        Units: <none>    Rate: 1.0   Alpha: PACK        Description: PACK AIR CONDITIONING ALL\n",
      "AOAI        Units: DEG       Rate: 4.0   Alpha: AOAI        Description: INDICATED ANGLE OF ATTACK\n",
      "AOAC        Units: DEG       Rate: 4.0   Alpha: AOAC        Description: CORRECTED ANGLE OF ATTACK\n",
      "BAL1        Units: FEET      Rate: 4.0   Alpha: BAL1        Description: BARO CORRECT ALTITUDE LSP\n",
      "APUF        Units: <none>    Rate: 2.0   Alpha: APUF        Description: APU FIRE WARNING\n",
      "TOCW        Units: <none>    Rate: 2.0   Alpha: TOCW        Description: TAKEOFF CONF WARNING\n",
      "BAL2        Units: FEET      Rate: 4.0   Alpha: BAL2        Description: BARO CORRECT ALTITUDE LSP\n",
      "WSHR        Units: <none>    Rate: 1.0   Alpha: WSHR        Description: WINDSHEAR WARNING\n",
      "WOW         Units: <none>    Rate: 1.0   Alpha: WOW         Description: WEIGHT ON WHEELS\n",
      "N2_1        Units: %RPM      Rate: 4.0   Alpha: N2.1        Description: CORE SPEED 1 LSP\n",
      "N2_2        Units: %RPM      Rate: 4.0   Alpha: N2.2        Description: CORE SPEED 2 LSP\n",
      "N2_3        Units: %RPM      Rate: 4.0   Alpha: N2.3        Description: CORE SPEED 3 LSP\n",
      "N2_4        Units: %RPM      Rate: 4.0   Alpha: N2.4        Description: CORE SPEED 4 LSP\n",
      "TAT         Units: DEG       Rate: 1.0   Alpha: TAT         Description: TOTAL AIR TEMPERATURE\n",
      "SAT         Units: DEG       Rate: 1.0   Alpha: SAT         Description: STATIC AIR TEMPERATURE\n",
      "N1T         Units: %RPM      Rate: 4.0   Alpha: N1T         Description: N1 TARGET LSP\n",
      "N1C         Units: %RPM      Rate: 4.0   Alpha: N1C         Description: N1 COMMAND LSP\n",
      "RUDD        Units: DEG       Rate: 2.0   Alpha: RUDD        Description: RUDDER POSITION\n",
      "FQTY_3      Units: LSB       Rate: 1.0   Alpha: FQTY.3      Description: FUEL QUANTITY TANK 3 LSB\n",
      "OIP_1       Units: PSI       Rate: 1.0   Alpha: OIP.1       Description: OIL PRESSURE 1\n",
      "OIP_2       Units: PSI       Rate: 1.0   Alpha: OIP.2       Description: OIL PRESSURE 2\n",
      "FQTY_4      Units: LSB       Rate: 1.0   Alpha: FQTY.4      Description: FUEL QUANTITY TANK 4 LSB\n",
      "CRSS        Units: DEG       Rate: 1.0   Alpha: CRSS        Description: SELECTED COURSE\n",
      "HDGS        Units: DEG       Rate: 1.0   Alpha: HDGS        Description: SELECTED HEADING\n",
      "ALTS        Units: FEET      Rate: 1.0   Alpha: ALTS        Description: SELECTED ALTITUDE LSP\n",
      "SNAP        Units: <none>    Rate: 1.0   Alpha: SNAP        Description: MANUAL SNAPSHOT SWITCH\n",
      "CASS        Units: KNOTS     Rate: 1.0   Alpha: CASS        Description: SELECTED AIRSPEED\n",
      "N1CO        Units: <none>    Rate: 1.0   Alpha: N1CO        Description: N1 COMPENSATION\n",
      "VSPS        Units: FT/MIN    Rate: 1.0   Alpha: VSPS        Description: SELECTED VERTICAL SPEED\n",
      "MNS         Units: MMACH     Rate: 1.0   Alpha: MNS         Description: SELECTED MACH\n",
      "MSQT_1      Units: <none>    Rate: 2.0   Alpha: MSQT.1      Description: SQUAT SWITCH LEFT MAIN GEAR\n",
      "VMODE       Units: <none>    Rate: 1.0   Alpha: VMODE       Description: VERTICAL ENGAGE MODES\n",
      "LMOD        Units: <none>    Rate: 1.0   Alpha: LMOD        Description: LATERAL ENGAGE MODES\n",
      "A_T         Units: <none>    Rate: 1.0   Alpha: A/T         Description: THRUST AUTOMATIC ON\n",
      "CCPC        Units: COUNTS    Rate: 2.0   Alpha: CCPC        Description: CONTROL COLUMN POSITION CAPT\n",
      "CCPF        Units: COUNTS    Rate: 2.0   Alpha: CCPF        Description: CONTROL COLUMN POSITION F/O\n",
      "RUDP        Units: COUNTS    Rate: 2.0   Alpha: RUDP        Description: RUDDER PEDAL POSITION\n",
      "CWPC        Units: COUNTS    Rate: 2.0   Alpha: CWPC        Description: CONTROL WHEEL POSITION CAPT\n",
      "CWPF        Units: COUNTS    Rate: 2.0   Alpha: CWPF        Description: CONTROL WHEEL POSITION F/O\n",
      "OIP_3       Units: PSI       Rate: 1.0   Alpha: OIP.3       Description: OIL PRESSURE 3\n",
      "OIP_4       Units: PSI       Rate: 1.0   Alpha: OIP.4       Description: OIL PRESSURE 4\n",
      "LOC         Units: DDM       Rate: 1.0   Alpha: LOC         Description: LOCALIZER DEVIATION\n",
      "GLS         Units: DDM       Rate: 1.0   Alpha: GLS         Description: GLIDESLOPE DEVIATION\n",
      "LONP        Units: DEG       Rate: 1.0   Alpha: LONP        Description: LONGITUDE POSITION LSP\n",
      "ABRK        Units: DEG       Rate: 1.0   Alpha: ABRK        Description: AIRBRAKE POSITION\n",
      "AIL_1       Units: DEG       Rate: 1.0   Alpha: AIL.1       Description: AILERON POSITION LH\n",
      "AIL_2       Units: DEG       Rate: 1.0   Alpha: AIL.2       Description: AILERON POSITION RH\n",
      "SPL_1       Units: DEG       Rate: 1.0   Alpha: SPL.1       Description: ROLL SPOILER LEFT\n",
      "SPL_2       Units: DEG       Rate: 1.0   Alpha: SPL.2       Description: ROLL SPOILER RIGHT\n",
      "ESN_4       Units: UNITS     Rate: 0.25  Alpha: ESN.4       Description: ENGINE SERIAL NUMBER 4 LSP\n",
      "ECYC_1      Units: HOURS     Rate: 0.25  Alpha: ECYC.1      Description: ENGINE CYCLE 1 LSP\n",
      "ECYC_2      Units: HOURS     Rate: 0.25  Alpha: ECYC.2      Description: ENGINE CYCLE 2 LSP\n",
      "ELEV_1      Units: DEG       Rate: 1.0   Alpha: ELEV.1      Description: ELEVATOR POSITION LEFT\n",
      "ELEV_2      Units: DEG       Rate: 1.0   Alpha: ELEV.2      Description: ELEVATOR POSITION RIGHT\n",
      "FLAP        Units: COUNTS    Rate: 1.0   Alpha: FLAP        Description: T.E. FLAP POSITION\n",
      "PTRM        Units: DEG       Rate: 1.0   Alpha: PTRM        Description: PITCH TRIM POSITION\n",
      "HF1         Units: <none>    Rate: 1.0   Alpha: HF1         Description: HF KEYING #1\n",
      "HF2         Units: <none>    Rate: 1.0   Alpha: HF2         Description: HF KEYING #2\n",
      "SMKB        Units: <none>    Rate: 1.0   Alpha: SMKB        Description: ANIMAL BAY SMOKE\n",
      "SPLY        Units: <none>    Rate: 1.0   Alpha: SPLY        Description: SPOILER DEPLOY YELLOW\n",
      "SPLG        Units: <none>    Rate: 1.0   Alpha: SPLG        Description: SPOILER DEPLOY GREEN\n",
      "FRMC        Units: <none>    Rate: 0.25  Alpha: FRMC        Description: FRAME COUNTER\n",
      "DVER_2      Units: <none>    Rate: 0.25  Alpha: DVER.2      Description: DATABASE ID VERSION CHAR 2\n",
      "ESN_3       Units: UNITS     Rate: 0.25  Alpha: ESN.3       Description: ENGINE SERIAL NUMBER 3 LSP\n",
      "BPGR_1      Units: PSI       Rate: 1.0   Alpha: BPGR.1      Description: BRAKE PRESSURE LH GREEN\n",
      "BPGR_2      Units: PSI       Rate: 1.0   Alpha: BPGR.2      Description: BRAKE PRESSURE RH GREEN\n",
      "BPYR_1      Units: PSI       Rate: 1.0   Alpha: BPYR.1      Description: BRAKE PRESSURE LH YELLOW\n",
      "BPYR_2      Units: PSI       Rate: 1.0   Alpha: BPYR.2      Description: BRAKE PRESSURE RH YELLOW\n",
      "ECYC_3      Units: HOURS     Rate: 0.25  Alpha: ECYC.3      Description: ENGINE CYCLE 3 LSP\n",
      "ECYC_4      Units: HOURS     Rate: 0.25  Alpha: ECYC.4      Description: ENGINE CYCLE 4 LSP\n",
      "EHRS_1      Units: HOURS     Rate: 0.25  Alpha: EHRS.1      Description: ENGINE HOURS 1 LSP\n",
      "TCAS        Units: <none>    Rate: 1.0   Alpha: TCAS        Description: TCAS LSP  \n",
      "GPWS        Units: <none>    Rate: 1.0   Alpha: GPWS        Description: GPWS 1-5  \n",
      "TMAG        Units: <none>    Rate: 1.0   Alpha: TMAG        Description: TRUE/MAG HEADING SELECT\n",
      "TAI         Units: <none>    Rate: 1.0   Alpha: TAI         Description: TAIL ANTICE ON\n",
      "WAI_1       Units: <none>    Rate: 1.0   Alpha: WAI.1       Description: INNER WING DEICE\n",
      "WAI_2       Units: <none>    Rate: 1.0   Alpha: WAI.2       Description: OUTER WING ANTICE\n",
      "DWPT        Units: <none>    Rate: 1.0   Alpha: DWPT        Description: DISTANCE TO WAYPOINT LSP\n",
      "OIPL        Units: <none>    Rate: 1.0   Alpha: OIPL        Description: LOW OIL PRESSURE ALL ENGINES\n",
      "FADF        Units: <none>    Rate: 1.0   Alpha: FADF        Description: FADEC FAIL ALL ENGINES\n",
      "FADS        Units: <none>    Rate: 1.0   Alpha: FADS        Description: FADEC STATUS ALL ENGINES\n",
      "EHRS_4      Units: HOURS     Rate: 0.25  Alpha: EHRS.4      Description: ENGINE HOURS 4 LSP\n",
      "EHRS_3      Units: HOURS     Rate: 0.25  Alpha: EHRS.3      Description: ENGINE HOURS 3 LSP\n",
      "EHRS_2      Units: HOURS     Rate: 0.25  Alpha: EHRS.2      Description: ENGINE HOURS 2 LSP\n",
      "TMODE       Units: <none>    Rate: 1.0   Alpha: TMODE       Description: THRUST MODE\n",
      "ATEN        Units: <none>    Rate: 1.0   Alpha: ATEN        Description: A/T ENGAGE STATUS\n",
      "LATP        Units: DEG       Rate: 1.0   Alpha: LATP        Description: LATITUDE POSITION LSP\n",
      "FIRE_1      Units: <none>    Rate: 1.0   Alpha: FIRE.1      Description: ENGINE FIRE #1\n",
      "FIRE_2      Units: <none>    Rate: 1.0   Alpha: FIRE.2      Description: ENGINE FIRE #2\n",
      "FIRE_3      Units: <none>    Rate: 1.0   Alpha: FIRE.3      Description: ENGINE FIRE #3\n",
      "FIRE_4      Units: <none>    Rate: 1.0   Alpha: FIRE.4      Description: ENGINE FIRE #4\n",
      "FGC3        Units: <none>    Rate: 1.0   Alpha: FGC3        Description: DFGS STATUS 3\n",
      "ILSF        Units: <none>    Rate: 1.0   Alpha: ILSF        Description: ILS FREQUENCY LSP\n",
      "ESN_1       Units: UNITS     Rate: 0.25  Alpha: ESN.1       Description: ENGINE SERIAL NUMBER 1 LSP\n",
      "ESN_2       Units: UNITS     Rate: 0.25  Alpha: ESN.2       Description: ENGINE SERIAL NUMBER 2 LSP\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "for k in data1.keys():\n",
    "    #don't print the first \"__xxxx__\" parameters\n",
    "    if type(data1[k]) == np.ndarray:\n",
    "        u = data1[k][\"Units\"][0,0] \n",
    "        if u.shape[0] == 0: u = [\"<none>\"]\n",
    "        #metadata[file] = defaultdict(dict)\n",
    "        #metadata[file][k] = defaultdict(dict)\n",
    "        metadata[file][k] = {}\n",
    "        metadata[file][k]['Units']       = u[0]\n",
    "        metadata[file][k]['Rate']        = data1[k][\"Rate\"][0,0][0,0].astype('float')\n",
    "        metadata[file][k]['Alpha']       = data1[k][\"Alpha\"][0,0][0]\n",
    "        metadata[file][k]['Description'] = data1[k][\"Description\"][0,0][0]\n",
    "        #check to see if the \"units\" are blank and set to '<none>'\n",
    "        print(f'{k:12s}Units: {str(metadata[file][k][\"Units\"]):10s}Rate: {str(metadata[file][k][\"Rate\"]):5s}',\n",
    "                f'Alpha: {metadata[file][k][\"Alpha\"]:11s} Description: {metadata[file][k][\"Description\"]:10s}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadata[file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing metadata to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open((f'{file}.json'), 'w') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_2_df(mdata, param, samplesize):\n",
    "    '''This NASA matlab data is a dictionary of arrays of objects and this function\n",
    "    takes in a single dictionary word and parses the data into a pandas dataframe\n",
    "    '''\n",
    "    #create an array filled with NaNs so we don't fill in data with bad data yet.\n",
    "    d = np.empty(samplesize).reshape(-1,1)\n",
    "    d[:] = np.NaN\n",
    "    rate = mdata[param]['Rate'][0,0][0,0]\n",
    "    i = int(16/rate)\n",
    "    d[::i] = mdata[param]['data'][0,0].reshape(-1,1)\n",
    "\n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out the data rates compared to the GMT hour:minute:seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time of file: 0:0:0, -0.5 seconds\n",
      "Ending time of file: 0:0:0, 2.0 seconds\n",
      "AOA1 rate: 4\n",
      "GMT_sec rate: 2\n",
      "diff 2.5\n",
      "AOA1 sample size 2,752\n",
      "time sample size 1,376\n",
      "AOA1 calculated rate (samples/sec) 1100.8 Hz\n",
      "rate (AOA1 samples/time samples) 2.0\n"
     ]
    }
   ],
   "source": [
    "hour   = data1['GMT_HOUR']['data'][0,0].reshape(-1,1).astype(int)\n",
    "minute = data1['GMT_MINUTE']['data'][0,0].reshape(-1,1).astype(int)\n",
    "second = data1['GMT_SEC']['data'][0,0].reshape(-1,1).astype(int)\n",
    "\n",
    "#set t array as large as 16hz signal as NaNs then add actual time in GMT\n",
    "GMT = np.array(hour*3600 + minute*60 + second)\n",
    "\n",
    "clockstart = (f'{hour[0,0]}:{minute[0,0]}:{second[0,0]}')\n",
    "clockstop  = (f'{hour[-1,0]}:{minute[-1,0]}:{second[-1,0]}')\n",
    "clocktime  = [(f'{hour[i,0]}:{minute[i,0]}:{second[i,0]}') for i in range(hour.shape[0])]\n",
    "\n",
    "starttime = GMT[1,0] - 0.5\n",
    "stoptime  = GMT[-1,0] + 4*0.5\n",
    "diff = stoptime - starttime\n",
    "\n",
    "aoa1_rate = data1['AOA1']['Rate'][0,0][0,0]\n",
    "aoa1_data_size = data1['AOA1']['data'][0][0].shape[0] \n",
    "\n",
    "gmt_sec_rate = data1['GMT_SEC']['Rate'][0,0][0,0]\n",
    "\n",
    "timesamples = hour.shape[0]\n",
    "\n",
    "print(f'Starting time of file: {clockstart}, {starttime} seconds')\n",
    "print(f'Ending time of file: {clockstop}, {stoptime} seconds')\n",
    "print(f'AOA1 rate: {aoa1_rate}')\n",
    "print(f'GMT_sec rate: {gmt_sec_rate}')\n",
    "print(f'diff {diff}')\n",
    "print(f'AOA1 sample size {aoa1_data_size:,}')\n",
    "print(f'time sample size {timesamples:,}')\n",
    "print(f'AOA1 calculated rate (samples/sec) {aoa1_data_size/diff} Hz')\n",
    "print(f'rate (AOA1 samples/time samples) {aoa1_data_size/(timesamples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_318404/3544990671.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#find the first time GMTsecs transitions to a new time, this is reliable GMT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#it normally stays the same time for 6 seconds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGMT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#GMTsecs is 2 Hz or 0.5 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "hour   = data1['GMT_HOUR']['data'][0,0].reshape(-1,1).astype(int)\n",
    "minute = data1['GMT_MINUTE']['data'][0,0].reshape(-1,1).astype(int)\n",
    "second = data1['GMT_SEC']['data'][0,0].reshape(-1,1).astype(int)\n",
    "\n",
    "#set t array as large as 16hz signal as NaNs then add actual time in GMT\n",
    "GMT = np.array(hour*3600 + minute*60 + second)\n",
    "\n",
    "#matches the fastest 16 Hz (adding an extra amount above 16Hz found in the data\n",
    "t_delta = 0.0625 + 0.5/549/16#seconds. \n",
    "\n",
    "samplesize_16hz = data1['FPAC']['data'][0,0].shape[0]\n",
    "\n",
    "#the first GMTsecs\n",
    "t0 = GMT[0]\n",
    "\n",
    "#find the first time GMTsecs transitions to a new time, this is reliable GMT\n",
    "#it normally stays the same time for 6 seconds.\n",
    "i = min([i for i in range(12) if not t0 == GMT[i]])\n",
    "\n",
    "#GMTsecs is 2 Hz or 0.5 seconds\n",
    "timeoffset = 0.5*i\n",
    "\n",
    "#offset from the first reliable GMT\n",
    "starttime = GMT[i,0] - timeoffset \n",
    "\n",
    "stoptime = starttime + t_delta*(samplesize_16hz-1) \n",
    "\n",
    "#create a 16 Hz time column to line everything up and make it a pandas dataframe\n",
    "t16hz = np.linspace(starttime, stoptime, samplesize_16hz)\n",
    "df1 = pd.DataFrame(data={'time':t16hz})\n",
    "\n",
    "#adding GMT in seconds\n",
    "t = np.empty(samplesize_16hz).reshape(-1,1)\n",
    "t[:] = np.NaN\n",
    "t[::8] = GMT #every eighth element\n",
    "df1['GMTsecs'] = t\n",
    "\n",
    "#looping through all of the keys and creating a full Pandas DataFrame\n",
    "for k in data1.keys():\n",
    "    #don't print the first \"__xxxx__\" parameters\n",
    "    if type(data1[k]) == np.ndarray:\n",
    "       \n",
    "        df1[k] = mat_2_df(data1, k, samplesize_16hz)\n",
    "\n",
    "\n",
    "#removing the first set of unreliable GMT data so it starts cleanly\n",
    "df1 = df1[i*8:-1]\n",
    "df1.reset_index(inplace=True)\n",
    "df1.pop('index')\n",
    "\n",
    "#writing to a parquet file\n",
    "df1.to_parquet(path=(f'{file}.parquet'), compression='gzip')\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inconsistent GMT seconds\n",
    "\n",
    "\n",
    "### some of these GMT samples only have 11 samples instead of 12 like they should.  not sure why?\n",
    "For instance 43410 GMT is the first one to have 11 samples instead of 12.\n",
    "This made 43415.5 16hz time match up with 43416 GMT<br>\n",
    "If all other signals line up with the GMT secs then I should modify the 8 NaNs on all other signals to make the \n",
    "GMT signal (43416) line up with the 16hz 43416 time stamp\n",
    "\n",
    "## solved by adding 0.5/549/16 seconds to each 16Hz signal.  \n",
    "As seen below, if you round the 16Hz signal to nearest int when comparing GMTsecs and 16Hz they will align \n",
    "properly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mismatches!\n"
     ]
    }
   ],
   "source": [
    "#checking to ensure the times are lining up.\n",
    "df1 = pd.read_parquet(f'{file}.parquet')\n",
    "istart = 0\n",
    "istop = -1\n",
    "newsamplesize_16hz = df1.shape[0]\n",
    "\n",
    "#find the first non-NaN number in GMTsecs\n",
    "t0 = [df1[\"GMTsecs\"][i] for i in range(istart,istart+8) if not np.isnan(df1[\"GMTsecs\"][i])][0]\n",
    "\n",
    "mismatch = False\n",
    "\n",
    "for i in range(newsamplesize_16hz):\n",
    "    gmtsecs = df1[\"GMTsecs\"][i]\n",
    "    hz16 = df1[\"time\"][i]\n",
    "    hzorig = hz16 \n",
    "    \n",
    "    #compare to previous GMTsecs to see when it changes and if it matches up\n",
    "    # with the 16Hz signal time when it does change\n",
    "    if not np.isnan(gmtsecs) and not t0 == gmtsecs:\n",
    "        #compare integer values\n",
    "        hz16 = round(hz16,0)\n",
    "        gmtsecs = round(gmtsecs,0)\n",
    "        t0 = gmtsecs\n",
    "        if not gmtsecs == hz16:\n",
    "            print(f'gmtsecs={gmtsecs}, 16Hz = {hz16}, 16Hzorig={round(hzorig,0)}')\n",
    "            mismatch = True\n",
    "        \n",
    "if not mismatch: print('No mismatches!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_1107</th>\n",
       "      <th>VAR_2670</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR_1107  VAR_2670\n",
       "1       NaN         3"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanline = pd.DataFrame({\"VAR_1107\": np.nan},index=[0])\n",
    "nanline\n",
    "nanline[\"VAR_2670\"] = 3\n",
    "nanline.index = [1]\n",
    "nanline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_1107</th>\n",
       "      <th>VAR_2670</th>\n",
       "      <th>VAR_5107</th>\n",
       "      <th>VAR_6670</th>\n",
       "      <th>FPAC</th>\n",
       "      <th>BLAC</th>\n",
       "      <th>CTAC</th>\n",
       "      <th>TH</th>\n",
       "      <th>MH</th>\n",
       "      <th>EGT_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ATEN</th>\n",
       "      <th>LATP</th>\n",
       "      <th>FIRE_1</th>\n",
       "      <th>FIRE_2</th>\n",
       "      <th>FIRE_3</th>\n",
       "      <th>FIRE_4</th>\n",
       "      <th>FGC3</th>\n",
       "      <th>ILSF</th>\n",
       "      <th>ESN_1</th>\n",
       "      <th>ESN_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR_1107  VAR_2670  VAR_5107  VAR_6670  FPAC  BLAC  CTAC  TH  MH  EGT_1  \\\n",
       "1       NaN       NaN       NaN       NaN   NaN   NaN   NaN NaN NaN    NaN   \n",
       "\n",
       "   ...  ATEN  LATP  FIRE_1  FIRE_2  FIRE_3  FIRE_4  FGC3  ILSF  ESN_1  ESN_2  \n",
       "1  ...   NaN   NaN     NaN     NaN     NaN     NaN   NaN   NaN    NaN    NaN  \n",
       "\n",
       "[1 rows x 186 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanline = [np.nan for k in data1.keys() if type(data1[k] == np.ndarray)]\n",
    "#for k in data1.keys():\n",
    "#    #don't print the first \"__xxxx__\" parameters\n",
    "#    if type(data1[k]) == np.ndarray:\n",
    "#       \n",
    "#        nanline[k] = np.nan\n",
    "nanline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43404.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istart = 5660\n",
    "#t0 = [df1[\"GMTsecs\"][i] for i in range(istart,istart+8) if np.isreal(df1[\"GMTsecs\"][i]) ]\n",
    "t0 = [df1[\"GMTsecs\"][i] for i in range(istart,istart+8) if not np.isnan(df1[\"GMTsecs\"][i])][0]\n",
    "\n",
    "t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(t0[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each file represents a single flight "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking to see if each successive file is ordered in time.\n",
    "  It is, but I found a few that had mislabeled names for their time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "data0 = loadmat('Tail_687_1/687200103200323.mat')\n",
    "data01 = loadmat('Tail_687_1/687200103200350.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First file:2165:25:45 Start: 45.0:165.0:90.0, Stop 45.0:165.0:90.0\n",
      "Second file:2165:25:45 Start: 45.0:165.0:90.0, Stop 45.0:165.0:90.0\n"
     ]
    }
   ],
   "source": [
    "#first file in Tail 687_1\n",
    "hour   = data0['GMT_HOUR'][0][0][0][:]\n",
    "minute = data0['GMT_MINUTE'][0][0][0][:]\n",
    "second = data0['GMT_SEC'][0][0][0][:]\n",
    "year   = data0['DATE_YEAR'][0][0][0][:]\n",
    "month  = data0['DATE_MONTH'][0][0][0][:]\n",
    "day    = data0['DATE_DAY'][0][0][0][:]\n",
    "h0s = hour[0][0].astype(float)\n",
    "m0s = minute[0][0].astype(float)\n",
    "s0s = second[0][0].astype(float)\n",
    "h0e = hour[-1][0].astype(float)\n",
    "m0e = minute[-1][0].astype(float)\n",
    "s0e = second[-1][0].astype(float)\n",
    "starttime = timedelta(hours=h0s, minutes=m0s, seconds=s0s)\n",
    "stoptime = timedelta(hours=h0e, minutes=m0e, seconds=s0e)\n",
    "#print(f'First file:{year[0,0]}:{month[0,0]}:{day[0,0]} Start: {starttime}, Stop {stoptime}')\n",
    "print(f'First file:{year[0,0]}:{month[0,0]}:{day[0,0]} Start: {h0s}:{m0s}:{s0s}, Stop {h0e}:{m0e}:{s0e}')\n",
    "\n",
    "#second file in Tail 687_1\n",
    "hour   = data01['GMT_HOUR'][0][0][0][:]\n",
    "minute = data01['GMT_MINUTE'][0][0][0][:]\n",
    "second = data01['GMT_SEC'][0][0][0][:]\n",
    "year   = data01['DATE_YEAR'][0][0][0][:]\n",
    "month  = data01['DATE_MONTH'][0][0][0][:]\n",
    "day    = data01['DATE_DAY'][0][0][0][:]\n",
    "h01s = hour[0][0].astype(float)\n",
    "m01s = minute[0][0].astype(float)\n",
    "s01s = second[0][0].astype(float)\n",
    "h01e = hour[-1][0].astype(float)\n",
    "m01e = minute[-1][0].astype(float)\n",
    "s01e = second[-1][0].astype(float)\n",
    "starttime = timedelta(hours=h01s, minutes=m01s, seconds=s01s)\n",
    "stoptime = timedelta(hours=h01e, minutes=m01e, seconds=s01e)\n",
    "\n",
    "print(f'Second file:{year[0,0]}:{month[0,0]}:{day[0,0]} Start: {h01s}:{m01s}:{s01s}, Stop {h01e}:{m01e}:{s01e}')\n",
    "#print(f'Second file:{year[0,0]}:{month[0,0]}:{day[0,0]} Start: {starttime}, Stop {stoptime}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2165], dtype=uint16)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>GMTsecs</th>\n",
       "      <th>VAR_1107</th>\n",
       "      <th>VAR_2670</th>\n",
       "      <th>VAR_5107</th>\n",
       "      <th>VAR_6670</th>\n",
       "      <th>FPAC</th>\n",
       "      <th>BLAC</th>\n",
       "      <th>CTAC</th>\n",
       "      <th>TH</th>\n",
       "      <th>...</th>\n",
       "      <th>ATEN</th>\n",
       "      <th>LATP</th>\n",
       "      <th>FIRE_1</th>\n",
       "      <th>FIRE_2</th>\n",
       "      <th>FIRE_3</th>\n",
       "      <th>FIRE_4</th>\n",
       "      <th>FGC3</th>\n",
       "      <th>ILSF</th>\n",
       "      <th>ESN_1</th>\n",
       "      <th>ESN_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43055.5000</td>\n",
       "      <td>43050.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>2632.0</td>\n",
       "      <td>3513.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-148.206635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.880527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8007.0</td>\n",
       "      <td>7958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43055.5625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43055.6250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43055.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43055.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-148.173676</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125307</th>\n",
       "      <td>50887.1875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125308</th>\n",
       "      <td>50887.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>134.529068</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125309</th>\n",
       "      <td>50887.3125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125310</th>\n",
       "      <td>50887.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005862</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125311</th>\n",
       "      <td>50887.4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>-0.006839</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125312 rows  188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  GMTsecs  VAR_1107  VAR_2670  VAR_5107  VAR_6670      FPAC  \\\n",
       "0       43055.5000  43050.0     584.0    1465.0    2632.0    3513.0  0.000000   \n",
       "1       43055.5625      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "2       43055.6250      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "3       43055.6875      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "4       43055.7500      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "...            ...      ...       ...       ...       ...       ...       ...   \n",
       "125307  50887.1875      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "125308  50887.2500      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "125309  50887.3125      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "125310  50887.3750      NaN       NaN       NaN       NaN       NaN  0.000000   \n",
       "125311  50887.4375      NaN       NaN       NaN       NaN       NaN -0.000977   \n",
       "\n",
       "            BLAC      CTAC          TH  ...  ATEN       LATP  FIRE_1  FIRE_2  \\\n",
       "0      -0.007816  0.000000 -148.206635  ...   0.0  44.880527     0.0     0.0   \n",
       "1      -0.010747  0.000000         NaN  ...   NaN        NaN     NaN     NaN   \n",
       "2      -0.007816  0.000000         NaN  ...   NaN        NaN     NaN     NaN   \n",
       "3      -0.006839  0.000000         NaN  ...   NaN        NaN     NaN     NaN   \n",
       "4      -0.009770  0.000000 -148.173676  ...   NaN        NaN     NaN     NaN   \n",
       "...          ...       ...         ...  ...   ...        ...     ...     ...   \n",
       "125307 -0.006839  0.000000         NaN  ...   NaN        NaN     NaN     NaN   \n",
       "125308 -0.007816  0.000000  134.529068  ...   NaN        NaN     NaN     NaN   \n",
       "125309 -0.005862  0.000000         NaN  ...   NaN        NaN     NaN     NaN   \n",
       "125310 -0.005862 -0.000977         NaN  ...   NaN        NaN     NaN     NaN   \n",
       "125311 -0.006839 -0.000977         NaN  ...   NaN        NaN     NaN     NaN   \n",
       "\n",
       "        FIRE_3  FIRE_4   FGC3   ILSF   ESN_1   ESN_2  \n",
       "0          0.0     0.0  120.0  100.0  8007.0  7958.0  \n",
       "1          NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "2          NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "3          NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "4          NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "...        ...     ...    ...    ...     ...     ...  \n",
       "125307     NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "125308     NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "125309     NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "125310     NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "125311     NaN     NaN    NaN    NaN     NaN     NaN  \n",
       "\n",
       "[125312 rows x 188 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_parquet(path='Tail_687_1_687200104111158.parquet')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting elevation values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14936/2716230373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ALT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maltr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ALTR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mralt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RALT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#calt = data1['CALT']['data'][0,0].reshape(1,-1)[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "alt = data1['ALT']['data'][0,0].reshape(1,-1)[0]\n",
    "altr = data1['ALTR']['data'][0,0].reshape(1,-1)[0]\n",
    "ralt = data1['RALT']['data'][0,0].reshape(1,-1)[0]\n",
    "#calt = data1['CALT']['data'][0,0].reshape(1,-1)[0]\n",
    "\n",
    "nsamples = data1['ALT']['data'][0,0].shape[0]\n",
    "rsamples = data1['RALT']['data'][0,0].shape[0]\n",
    "\n",
    "xs = np.linspace(1,nsamples,nsamples)\n",
    "\n",
    "xr = np.linspace(1,nsamples,rsamples)\n",
    "\n",
    "#alt = alt.astype(np.int)\n",
    "#alt, x\n",
    "\n",
    "\n",
    "#alt = data1['ALT']['data'][0,0]\n",
    "\n",
    "fig1 = plt.figure(figsize=(20, 15))\n",
    "\n",
    "\n",
    "plt.plot(xs, alt, 'r-', label='alt')\n",
    "plt.plot(xs, altr, 'b-', label='altr')\n",
    "plt.plot(xr, ralt, 'g-', label='altr')\n",
    "#ax=plt.subplot(aspect='equal')\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "ax.set_title('Elevation')\n",
    "plt.label()\n",
    "#plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "\n",
    "\n",
    "#plt.xlim([xmin, xmax])\n",
    "#plt.ylim([ymin, ymax])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RALT min/max: -3.625/5,500.0\n",
      "Number of RALT samples: 52,992\n",
      "CALT min/max: 0/0\n",
      "Number of CALT samples: 6,624\n",
      "ALTR min/max: -3,632/3,968\n",
      "Number of ALTR samples: 26,496\n",
      "ALTS min/max: 3,500/33,100\n",
      "Number of ALTS samples: 6,624\n",
      "ALT min/max: 470/33,025\n",
      "Number of ALT samples: 26,496\n"
     ]
    }
   ],
   "source": [
    "ralt = data.get('RALT')\n",
    "print(f'RALT min/max: {min(ralt[0][0][0])[0]}/{max(ralt[0][0][0])[0]:,}')\n",
    "print(f'Number of RALT samples: {ralt[0][0][0].shape[0]:,}')\n",
    "\n",
    "calt = data.get('CALT')\n",
    "print(f'CALT min/max: {min(calt[0][0][0])[0]}/{max(calt[0][0][0])[0]:,}')\n",
    "print(f'Number of CALT samples: {calt[0][0][0].shape[0]:,}')\n",
    "\n",
    "altr = data.get('ALTR')\n",
    "print(f'ALTR min/max: {min(altr[0][0][0])[0]:,}/{max(altr[0][0][0])[0]:,}')\n",
    "print(f'Number of ALTR samples: {altr[0][0][0].shape[0]:,}')\n",
    "\n",
    "alts = data.get('ALTS')\n",
    "print(f'ALTS min/max: {min(alts[0][0][0])[0]:,}/{max(alts[0][0][0])[0]:,}')\n",
    "print(f'Number of ALTS samples: {alts[0][0][0].shape[0]:,}')\n",
    "\n",
    "alt = data.get('ALT')\n",
    "print(f'ALT min/max: {min(alt[0][0][0])[0]}/{max(alt[0][0][0])[0]:,}')\n",
    "print(f'Number of ALT samples: {alt[0][0][0].shape[0]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples of MACH: 31,328\n",
      "rate of MACH: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'samples of MACH: {np.size(data1.get(\"MACH\")[0][0][0]):,}')\n",
    "print(f'rate of MACH: {np.size(data1[\"MACH\"][\"Rate\"][0, 0][0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APFD is Auto Pilot Flight Director Status and is \"probably\" 0 when it's on the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data1['APFD']['data'][0,0][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Velocity shows that it's on the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73124098777771"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data1['MACH']['data'][0,0][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('Tail_687_1/687200109140804.mat')\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APFD shows that this is not on the ground the whole time and has a bit of all states in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=uint8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data.get('APFD')[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Velocity shows that it's NOT on the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73243797])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data.get('MACH')[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing all of the available keys in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'VAR_1107', 'VAR_2670', 'VAR_5107', 'VAR_6670', 'FPAC', 'BLAC', 'CTAC', 'TH', 'MH', 'EGT_1', 'EGT_2', 'EGT_3', 'EGT_4', 'IVV', 'GS', 'TRK', 'TRKM', 'DA', 'POVT', 'WS', 'MW', 'DFGS', 'WD', 'ALT', 'NSQT', 'RALT', 'ALTR', 'FQTY_1', 'OIT_1', 'OIT_2', 'AOA1', 'AOA2', 'PTCH', 'FF_1', 'PSA', 'FF_2', 'FF_3', 'ROLL', 'FF_4', 'N1_1', 'N1_2', 'MACH', 'CAS', 'APFD', 'PH', 'CASM', 'TAS', 'VRTG', 'LATG', 'PI', 'PS', 'N1_3', 'EVNT', 'MRK', 'VIB_1', 'PT', 'VHF1', 'VHF2', 'LGDN', 'LGUP', 'VIB_2', 'VHF3', 'PUSH', 'SHKR', 'MSQT_2', 'VIB_3', 'LONG', 'PLA_1', 'N1_4', 'HYDY', 'HYDG', 'SMOK', 'CALT', 'VIB_4', 'PLA_2', 'PLA_3', 'PLA_4', 'GMT_HOUR', 'GMT_MINUTE', 'GMT_SEC', 'ACMT', 'FQTY_2', 'OIT_3', 'OIT_4', 'DATE_YEAR', 'DATE_MONTH', 'DATE_DAY', 'DVER_1', 'ACID', 'BLV', 'EAI', 'PACK', 'AOAI', 'AOAC', 'BAL1', 'APUF', 'TOCW', 'BAL2', 'WSHR', 'WOW', 'N2_1', 'N2_2', 'N2_3', 'N2_4', 'TAT', 'SAT', 'N1T', 'N1C', 'RUDD', 'FQTY_3', 'OIP_1', 'OIP_2', 'FQTY_4', 'CRSS', 'HDGS', 'ALTS', 'SNAP', 'CASS', 'N1CO', 'VSPS', 'MNS', 'MSQT_1', 'VMODE', 'LMOD', 'A_T', 'CCPC', 'CCPF', 'RUDP', 'CWPC', 'CWPF', 'OIP_3', 'OIP_4', 'LOC', 'GLS', 'LONP', 'ABRK', 'AIL_1', 'AIL_2', 'SPL_1', 'SPL_2', 'ESN_4', 'ECYC_1', 'ECYC_2', 'ELEV_1', 'ELEV_2', 'FLAP', 'PTRM', 'HF1', 'HF2', 'SMKB', 'SPLY', 'SPLG', 'FRMC', 'DVER_2', 'ESN_3', 'BPGR_1', 'BPGR_2', 'BPYR_1', 'BPYR_2', 'ECYC_3', 'ECYC_4', 'EHRS_1', 'TCAS', 'GPWS', 'TMAG', 'TAI', 'WAI_1', 'WAI_2', 'DWPT', 'OIPL', 'FADF', 'FADS', 'EHRS_4', 'EHRS_3', 'EHRS_2', 'TMODE', 'ATEN', 'LATP', 'FIRE_1', 'FIRE_2', 'FIRE_3', 'FIRE_4', 'FGC3', 'ILSF', 'ESN_1', 'ESN_2'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not sure what some of these values are so i'm printing them here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disecting a single name in the dictionary that includes data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data names in AOA1: ('data', 'Rate', 'Units', 'Description', 'Alpha')\n",
      "Number of AOA1 samples in dataset = 26,496\n",
      "A0A1 data: [-4.1747733  -4.1747733  -4.21871861 ... -3.60349187 -3.55954656\n",
      " -3.55954656]\n",
      "A0A1 Rate: 4\n",
      "A0A1 Units: DEG\n",
      "A0A1 Description: ANGLE OF ATTACK 1\n",
      "A0A1 Alpha: AOA1\n",
      "\n",
      "Pandas DataFrame:\n",
      "           AOA1\n",
      "0     -4.174773\n",
      "1     -4.174773\n",
      "2     -4.218719\n",
      "3     -4.174773\n",
      "4     -4.218719\n",
      "...         ...\n",
      "26491 -3.603492\n",
      "26492 -3.603492\n",
      "26493 -3.603492\n",
      "26494 -3.559547\n",
      "26495 -3.559547\n",
      "\n",
      "[26496 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mdata = data['AOA1']\n",
    "mdtype = mdata.dtype #objects in mat file\n",
    "\n",
    "print(f'Data names in AOA1: {mdtype.names}')\n",
    "\n",
    "ndata = {n: mdata[n][0, 0] for n in mdtype.names}\n",
    "\n",
    "\n",
    "#[print(f'A0A1 {r}: {ndata[r]}') for r in mdtype.names]\n",
    "\n",
    "aoa_data =        ndata['data'].reshape(1,-1)[0]\n",
    "aoa_rate =        ndata[\"Rate\"][0][0]\n",
    "aoa_units =       ndata[\"Units\"][0]\n",
    "aoa_description = ndata[\"Description\"][0]\n",
    "aoa_alpha =       ndata[\"Alpha\"][0]\n",
    "\n",
    "aoa_samples = data[\"AOA1\"][0][0][0].shape[0]\n",
    "\n",
    "print(f'Number of AOA1 samples in dataset = {aoa_samples:,}')\n",
    "print(f'A0A1 data: {aoa_data}')\n",
    "print(f'A0A1 Rate: {aoa_rate}')\n",
    "print(f'A0A1 Units: {aoa_units}')\n",
    "print(f'A0A1 Description: {aoa_description}')\n",
    "print(f'A0A1 Alpha: {aoa_alpha}')\n",
    "\n",
    "\n",
    "d = {'AOA1': aoa_data}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(f'\\nPandas DataFrame:\\n{df}');\n",
    "#dft = pd.DataFrame.from_dict(ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RALT']['Units'][0, 0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26496.0"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "52992/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Angles of Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoa1 = data.get('AOA1')[0][0][0][:]\n",
    "print(f'AOA1 min/max: {min(aoa1)[0]:.2f}/{max(aoa1)[0]:.2f}')\n",
    "aoa2 = data.get('AOA2')[0][0][0][:]\n",
    "print(f'AOA2 min/max: {min(aoa2)[0]:.2f}/{max(aoa2)[0]:.2f}')\n",
    "pitch = data.get('PTCH')[0][0][0][:]\n",
    "print(f'PTCH min/max: {min(pitch)[0]:.2f}/{max(pitch)[0]:.2f}')\n",
    "aoaI = data.get('AOAI')[0][0][0][:]\n",
    "print(f'AOAI min/max: {min(aoaI)[0]:.2f}/{max(aoaI)[0]:.2f}')\n",
    "aoaC = data.get('AOAC')[0][0][0][:]\n",
    "print(f'AOAC min/max: {min(aoaC)[0]:.2f}/{max(aoaC)[0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll = data.get('ROLL')[0][0][0][:]\n",
    "print(f'ROLL min/max: {min(roll)[0]:.2f}/{max(roll)[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Data contained within the Matlab dictionaries\n",
    "I'm not sure what this extra data means, but the first 2 array indicies of each of these dictionary values are\n",
    "empty.  This may be a good chance to rewrite them as panda parquet files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otherdata1=[[4]]\n",
      "otherdata2=[[4]]\n",
      "otherdata3=[[8]]\n",
      "otherdata4=[[4]]\n",
      "otherdata5=[[4]]\n"
     ]
    }
   ],
   "source": [
    "otherdata1 = data.get('AOA1')[0][0][1][:]\n",
    "otherdata2 = data.get('AOA2')[0][0][1][:]\n",
    "otherdata3 = data.get('PTCH')[0][0][1][:]\n",
    "otherdata4 = data.get('AOAI')[0][0][1][:]\n",
    "otherdata5 = data.get('AOAC')[0][0][1][:]\n",
    "print(f'otherdata1={otherdata1}')\n",
    "print(f'otherdata2={otherdata2}')\n",
    "print(f'otherdata3={otherdata3}')\n",
    "print(f'otherdata4={otherdata4}')\n",
    "print(f'otherdata5={otherdata5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different Altitude measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RALT min/max: -3.625/5,500.0\n",
      "Number of RALT samples: 52,992\n",
      "CALT min/max: 0/0\n",
      "Number of CALT samples: 6,624\n",
      "ALTR min/max: -3,632/3,968\n",
      "Number of ALTR samples: 26,496\n",
      "ALTS min/max: 3,500/33,100\n",
      "Number of ALTS samples: 6,624\n",
      "ALT min/max: 470/33,025\n",
      "Number of ALT samples: 26,496\n"
     ]
    }
   ],
   "source": [
    "ralt = data.get('RALT')\n",
    "print(f'RALT min/max: {min(ralt[0][0][0])[0]}/{max(ralt[0][0][0])[0]:,}')\n",
    "print(f'Number of RALT samples: {ralt[0][0][0].shape[0]:,}')\n",
    "\n",
    "calt = data.get('CALT')\n",
    "print(f'CALT min/max: {min(calt[0][0][0])[0]}/{max(calt[0][0][0])[0]:,}')\n",
    "print(f'Number of CALT samples: {calt[0][0][0].shape[0]:,}')\n",
    "\n",
    "altr = data.get('ALTR')\n",
    "print(f'ALTR min/max: {min(altr[0][0][0])[0]:,}/{max(altr[0][0][0])[0]:,}')\n",
    "print(f'Number of ALTR samples: {altr[0][0][0].shape[0]:,}')\n",
    "\n",
    "alts = data.get('ALTS')\n",
    "print(f'ALTS min/max: {min(alts[0][0][0])[0]:,}/{max(alts[0][0][0])[0]:,}')\n",
    "print(f'Number of ALTS samples: {alts[0][0][0].shape[0]:,}')\n",
    "\n",
    "alt = data.get('ALT')\n",
    "print(f'ALT min/max: {min(alt[0][0][0])[0]}/{max(alt[0][0][0])[0]:,}')\n",
    "print(f'Number of ALT samples: {alt[0][0][0].shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Day, Month, Year look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of Date_Year:  2001\n",
      "Unique values of Date_Month: 9\n",
      "Unique values of Date_Day:   14\n"
     ]
    }
   ],
   "source": [
    "year  = data.get('DATE_YEAR')[0][0][0][:]\n",
    "month = data.get('DATE_MONTH')[0][0][0][:]\n",
    "day   = data.get('DATE_DAY')[0][0][0][:]\n",
    "\n",
    "print(f'Unique values of Date_Year:  {np.unique(year)[0]}')\n",
    "print(f'Unique values of Date_Month: {np.unique(month)[0]}')\n",
    "print(f'Unique values of Date_Day:   {np.unique(day)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like GMT time does not change in this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this GMT time does not make sense to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour   = data.get('GMT_HOUR')[0][0][0][:]\n",
    "minute = data.get('GMT_MINUTE')[0][0][0][:]\n",
    "second = data.get('GMT_SEC')[0][0][0][:]\n",
    "\n",
    "#figuring out what the \"rate\" means\n",
    "h1 = hour[0][0]\n",
    "m1 = minute[0][0]\n",
    "s1 = second[0][0]\n",
    "\n",
    "hour[-1][0]\n",
    "\n",
    "#print(f'Unique values of GMT Hour:   {np.unique(hour)}')\n",
    "#print(f'Unique values of GMT Minute: {np.unique(minute)}')\n",
    "#print(f'Unique values of GMT Second: {np.unique(second)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  2001\n",
      "Starting time of file: 6:44:36\n",
      "Ending time of file: 7:42:18\n",
      "AOA1 rate: 4\n",
      "AOA1 calc rate (samples/sec) 3.9976891969959563\n",
      "diff (secs) 3,462.0\n",
      "AOA1 sample size 13,840\n",
      "time sample size 6,920\n",
      "rate ratio (AOA1 samples/time samples) 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2001, 9, 14)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta, date\n",
    "\n",
    "d645 = loadmat('Tail_687_1/687200109140645.mat')\n",
    "hour   = d645['GMT_HOUR'][0][0][0][:]\n",
    "minute = d645['GMT_MINUTE'][0][0][0][:]\n",
    "second = d645['GMT_SEC'][0][0][0][:]\n",
    "year   = d645['DATE_YEAR'][0][0][0][:]\n",
    "month  = d645['DATE_MONTH'][0][0][0][:]\n",
    "day    = d645['DATE_DAY'][0][0][0][:]\n",
    "\n",
    "#figuring out what the \"rate\" means\n",
    "h1 = hour[0][0].astype(float)\n",
    "m1 = minute[0][0].astype(float)\n",
    "s1 = second[0][0].astype(float)\n",
    "\n",
    "starttime = timedelta(hours=h1, minutes=m1, seconds=s1)\n",
    "\n",
    "he = hour[-1][0].astype(float)\n",
    "me = minute[-1][0].astype(float)\n",
    "se = second[-1][0].astype(float)\n",
    "\n",
    "stoptime = timedelta(hours=he, minutes=me, seconds=se)\n",
    "\n",
    "timesamples = second.shape[0]\n",
    "\n",
    "\n",
    "diff = stoptime - starttime \n",
    "\n",
    "aoa1_rate = d645['AOA1']['Rate'][0][0][0][0]\n",
    "aoa1_data_size = d645['AOA1']['data'][0][0].shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Date:  {np.unique(year)[0]}')\n",
    "print(f'Starting time of file: {starttime}')\n",
    "print(f'Ending time of file: {stoptime}')\n",
    "print(f'AOA1 rate: {aoa1_rate}')\n",
    "print(f'AOA1 calc rate (samples/sec) {aoa1_data_size/diff.total_seconds()}')\n",
    "print(f'diff (secs) {diff.total_seconds():,}')\n",
    "print(f'AOA1 sample size {aoa1_data_size:,}')\n",
    "print(f'time sample size {timesamples:,}')\n",
    "print(f'rate ratio (AOA1 samples/time samples) {aoa1_data_size/(timesamples)}')\n",
    "\n",
    "\n",
    "date(np.unique(year)[0], np.unique(month)[0], np.unique(day)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3462"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoptime.seconds - starttime.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24276.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starttime.total_seconds()\n",
    "#starttime.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of data350: <class 'dict'>\n",
      "\n",
      "keys of data350: dict_keys(['__header__', '__version__', '__globals__', 'VAR_1107', 'VAR_2670', 'VAR_5107', 'VAR_6670', 'FPAC', 'BLAC', 'CTAC', 'TH', 'MH', 'EGT_1', 'EGT_2', 'EGT_3', 'EGT_4', 'IVV', 'GS', 'TRK', 'TRKM', 'DA', 'POVT', 'WS', 'MW', 'DFGS', 'WD', 'ALT', 'NSQT', 'RALT', 'ALTR', 'FQTY_1', 'OIT_1', 'OIT_2', 'AOA1', 'AOA2', 'PTCH', 'FF_1', 'PSA', 'FF_2', 'FF_3', 'ROLL', 'FF_4', 'N1_1', 'N1_2', 'MACH', 'CAS', 'APFD', 'PH', 'CASM', 'TAS', 'VRTG', 'LATG', 'PI', 'PS', 'N1_3', 'EVNT', 'MRK', 'VIB_1', 'PT', 'VHF1', 'VHF2', 'LGDN', 'LGUP', 'VIB_2', 'VHF3', 'PUSH', 'SHKR', 'MSQT_2', 'VIB_3', 'LONG', 'PLA_1', 'N1_4', 'HYDY', 'HYDG', 'SMOK', 'CALT', 'VIB_4', 'PLA_2', 'PLA_3', 'PLA_4', 'GMT_HOUR', 'GMT_MINUTE', 'GMT_SEC', 'ACMT', 'FQTY_2', 'OIT_3', 'OIT_4', 'DATE_YEAR', 'DATE_MONTH', 'DATE_DAY', 'DVER_1', 'ACID', 'BLV', 'EAI', 'PACK', 'AOAI', 'AOAC', 'BAL1', 'APUF', 'TOCW', 'BAL2', 'WSHR', 'WOW', 'N2_1', 'N2_2', 'N2_3', 'N2_4', 'TAT', 'SAT', 'N1T', 'N1C', 'RUDD', 'FQTY_3', 'OIP_1', 'OIP_2', 'FQTY_4', 'CRSS', 'HDGS', 'ALTS', 'SNAP', 'CASS', 'N1CO', 'VSPS', 'MNS', 'MSQT_1', 'VMODE', 'LMOD', 'A_T', 'CCPC', 'CCPF', 'RUDP', 'CWPC', 'CWPF', 'OIP_3', 'OIP_4', 'LOC', 'GLS', 'LONP', 'ABRK', 'AIL_1', 'AIL_2', 'SPL_1', 'SPL_2', 'ESN_4', 'ECYC_1', 'ECYC_2', 'ELEV_1', 'ELEV_2', 'FLAP', 'PTRM', 'HF1', 'HF2', 'SMKB', 'SPLY', 'SPLG', 'FRMC', 'DVER_2', 'ESN_3', 'BPGR_1', 'BPGR_2', 'BPYR_1', 'BPYR_2', 'ECYC_3', 'ECYC_4', 'EHRS_1', 'TCAS', 'GPWS', 'TMAG', 'TAI', 'WAI_1', 'WAI_2', 'DWPT', 'OIPL', 'FADF', 'FADS', 'EHRS_4', 'EHRS_3', 'EHRS_2', 'TMODE', 'ATEN', 'LATP', 'FIRE_1', 'FIRE_2', 'FIRE_3', 'FIRE_4', 'FGC3', 'ILSF', 'ESN_1', 'ESN_2'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data350 = loadmat('Tail_687_1/687200103200350.mat')\n",
    "print(f'type of data350: {type(data350)}\\n')\n",
    "print(f'keys of data350: {(data350.keys())}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not sure what some of these values are so i'm printing them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header = :b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Tue Jan 28 11:43:13 2014'\n",
      "version = :1.0\n",
      "globals = :[]\n"
     ]
    }
   ],
   "source": [
    "header = data350.get('__header__')\n",
    "version = data350.get('__version__')\n",
    "gs = data350.get('__globals__')\n",
    "print(f'header = :{header}')\n",
    "print(f'version = :{version}')\n",
    "print(f'globals = :{gs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Angles of Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique AOA1: [-3.64743718 -3.60349187 -3.55954656 -3.51560124 -3.47165593 -3.42771062\n",
      " -3.38376531]\n",
      "Unique AOA2: [-3.64743718 -3.60349187 -3.55954656 -3.51560124 -3.47165593 -3.42771062\n",
      " -3.38376531]\n",
      "Unique PTCH: [-3.64743718 -3.60349187 -3.55954656 -3.51560124 -3.47165593 -3.42771062\n",
      " -3.38376531]\n",
      "Unique AOAI: [-1.53807744 -1.49413213 -1.45018681 -1.4062415  -1.36229619 -1.31835088\n",
      " -1.27440556 -1.23046025 -1.18651494 -1.14256963 -1.09862431 -1.054679\n",
      " -1.01073369 -0.96678838 -0.92284306 -0.87889775 -0.83495244 -0.79100713\n",
      " -0.74706181 -0.7031165  -0.65917119 -0.61522588 -0.57128056 -0.52734288\n",
      " -0.48339757 -0.43945226 -0.39550694 -0.35156163 -0.30761632 -0.26367101]\n",
      "Unique AOAC: [0]\n"
     ]
    }
   ],
   "source": [
    "aoa1 = np.unique(data350.get('AOA1')[0][0][0][:])\n",
    "print(f'Unique AOA1: {aoa1}')\n",
    "aoa2 = np.unique(data350.get('AOA2')[0][0][0][:])\n",
    "print(f'Unique AOA2: {aoa1}')\n",
    "pitch = np.unique(data350.get('PTCH')[0][0][0][:])\n",
    "print(f'Unique PTCH: {aoa1}')\n",
    "aoaI = np.unique(data350.get('AOAI')[0][0][0][:])\n",
    "print(f'Unique AOAI: {aoaI}')\n",
    "aoaC = np.unique(data350.get('AOAC')[0][0][0][:])\n",
    "print(f'Unique AOAC: {aoaC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These two files appear to be \"created\" only 3 seconds apart\n",
    "However, I can't seem to find a good timestamp in this dictionary yet to determine if this is matlab timestamp\n",
    "or a recording timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year, month and days do not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of Date_Year:  [2165]\n",
      "Unique values of Date_Month: [25]\n",
      "Unique values of Date_Day:   [45]\n"
     ]
    }
   ],
   "source": [
    "year  = data350.get('DATE_YEAR')[0][0][0][:]\n",
    "month = data350.get('DATE_MONTH')[0][0][0][:]\n",
    "day   = data350.get('DATE_DAY')[0][0][0][:]\n",
    "\n",
    "print(f'Unique values of Date_Year:  {np.unique(year)}')\n",
    "print(f'Unique values of Date_Month: {np.unique(month)}')\n",
    "print(f'Unique values of Date_Day:   {np.unique(day)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like GMT time does not change in this data when the plane is on the ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMT time is set to these values when plane is on the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of GMT Hour:   45\n",
      "Unique values of GMT Minute: 165\n",
      "Unique values of GMT Second: 90\n"
     ]
    }
   ],
   "source": [
    "hour   = data350.get('GMT_HOUR')[0][0][0][:]\n",
    "minute = data350.get('GMT_MINUTE')[0][0][0][:]\n",
    "second = data350.get('GMT_SEC')[0][0][0][:]\n",
    "\n",
    "print(f'Unique values of GMT Hour:   {np.unique(hour)[0]}')\n",
    "print(f'Unique values of GMT Minute: {np.unique(minute)[0]}')\n",
    "print(f'Unique values of GMT Second: {np.unique(second)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to figure out if this is EGI time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of EGT1: 4960\n"
     ]
    }
   ],
   "source": [
    "egt1   = data350['EGT_1'][0][0][0][:]\n",
    "egt2   = data350['EGT_2'][0][0][0][:]\n",
    "egt3   = data350['EGT_3'][0][0][0][:]\n",
    "egt4   = data350['EGT_4'][0][0][0][:]\n",
    "\n",
    "print(f'Unique values of EGT1: {np.size(egt1)}')\n",
    "#print(f'Unique values of EGT2: {np.unique(egt2)}')\n",
    "#print(f'Unique values of EGT3: {np.unique(egt3)}')\n",
    "#print(f'Unique values of EGT4: {np.unique(egt4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
